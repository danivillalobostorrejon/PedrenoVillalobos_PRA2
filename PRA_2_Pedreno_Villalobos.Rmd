---
title: 'PRA2: Tipologia y Ciclo de Vida de los Datos'
author: "Daniel Villalobos Torrejon"
date: "5/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/UOC/1r/2n Semestre/Tipologia y ciclo de vida de los datos/PRA2") # choose your own directory

set.seed(12)

if(!require(mice)){
    install.packages("mice")
    library(mice)
}

if(!require(ROCR)){
    install.packages("ROCR")
    library(ROCR)
}
 
```


# Definición del proyecto



# Descripción del dataset

La base de datos que vamos a utilizar en estre práctica proviene de una institución bancária europea. Aunque estos datos se han encontradp en la página web UCI Machine Learning Repository. 

Las variables que se encuentran en este dataset son:

|Nombre| Tipo | Descripción | Valores |
|-------| ----| ------------| --------|
|age |Numérica| Edat de la persona contactada| |
| job| Categorica  nominal| Tipo de trabajo de la persona contactada| *Admin, blue-collar, entrepreneur, housemaid, management, retired, self-employed, services, Student, technician, unemployed*|
|marital |Categorica nominal|Estado civil de la persona contactada|*Divorced (divorciat/da o vidu/a), married, single*|
|education| Categorica  nominal|Nivel educativo de la persona contactada|*Basic.9y, high.school, professional.course, university.degree*|
|housing|Categorica binaria|Indica si la persona contactada tiene una hipoteca contratada|*Yes, no*|
|loan|Categorica binaria|Indica si la persona contactada tiene un crédito personal|*Yes, no*|
|contact|Categorica binaria|Tipo de comunicación que se ha realitzado|*Cellular, telephone*|
|month|Categorica nominal|Mes en que se ha contactado por última vez|*Jan, feb, ..., nov, dec*|
|day_of_week|Categorica nominal|Dia en que se ha contactat por última vez|*Mon, tue, wed, thu, fri.*|
|duration|Numérica contínua|Duración en segundos de el último contacto con la persona| |
|campaign|Numérica discreta|Número de veces que se ha contactado a la persona esta campaña| |
|previous|Numérica discreta|Número de veces que se ha contactado a la persona antes de esta campaña| |
|poutcome| Categorica nominal|Resultado de la campaña de marketing anterior|*Failure, nonexistent, success*|
|emp.var.rate|Numérica contínua|Tasa de varicación de la ocupación del momento en que se ha contactado (Indicador trimestral)| |
|cons.price.idx|Numérica contínua|Indice de precio del consumidor (Indicador mensual)| |
|cons.conf.idx|Numérica contínua |Indice de confianza del consumidor (Indicador mensual)| |
|euribor3m|Numérica contínua|Euribor a 3 meses en el dia del contacto (Indicador diario)| |
|nr.employed|Numérica discreta|Número de trabajadores en la entidad bancaria en el momento del contacto| |
|y|Categorica binaria|Indica si el cliente ha contratado un diposito bancario durante esta campaña|*Yes, no*|


Se han eliminado dos variables de la base de datos original (*default* y *pdays*), ya que, en el primer caso no se sabia interpretar el significado de la variable, y en el segundo caso porque no aportaba más información que la que ya aporta la variable *previous*.

Como se puede esperar la variable respuesta que utilizaremos será, el conocer si un cliente contratará el crédito durante la campaña o no. En la base de datos esta información esta recogida en la variable *y*.

# Integración y selección de los datos de interés a analizar

Para empezar el análisis primero debemos realizar una lectura de los datos:

```{r}
bd <- read.csv2("bank-additional-full.csv")
head(bd)
```

# Limpieza de los datos.

### Representación gráfica
```{r}
hist(bd$age)
```


```{r}
barplot(prop.table(table(bd$job)))
```

Podemos obervar como tenemos `r length(which(bd$job == "unknown"))` de valores *unknown*


```{r}
barplot(100*prop.table(table(bd$marital)))
```

Podemos obervar como tenemos `r length(which(bd$marital == "unknown"))` de valores *unknown*

```{r}
barplot(100*prop.table(table(bd$education)))
```


```{r}
barplot(100*prop.table(table(bd$housing)))
```

Podemos obervar como tenemos `r length(which(bd$housing == "unknown"))` de valores *unknown*


```{r}
barplot(100*prop.table(table(bd$loan)))
```


Podemos obervar como tenemos `r length(which(bd$loan == "unknown"))` de valores *unknown*

```{r}
barplot(100*prop.table(table(bd$contact)))
```


```{r}
barplot(100*prop.table(table(bd$month)))
```


```{r}
barplot(100*prop.table(table(bd$day_of_week)))
```


```{r}
hist(bd$duration)
```


```{r}
hist(bd$campaign)
```


```{r}
hist(bd$previous)
```


```{r}
barplot(table(bd$poutcome))
```


```{r}
table(bd$emp.var.rate) #VARIACIÓ TREBALL TRIMESTRAL
```


```{r}
table(bd$cons.price.idx) #IPC MENSUAL
```


```{r}
table(bd$cons.conf.idx) # INDEX CONFIANÇA CONSUMIDOR
```


```{r}
table(bd$euribor3m) #EURIBOR A TRES MESOS PER DIA
```


```{r}
table(bd$nr.employed) #TREBALLADOR PER TRIMESTRE
```

### Conteo de missings i eliminación

Realizaremos un breve análisis de los valores missings en cada uno de los registros, esto nos dara un poco más de información de como esta estructurada la base de datos.

```{r}
for (i in 1:nrow(bd)){
  
  bd$na_count[i] <- sum(bd[i,] == 'unknown') 
  
}
table(bd$na_count)
```

Como se muestra en la tabla de arriba, hay registros con hasta 5 valores missing, de los cuales, aquellos que tengan más de 3 valores faltantes por registro, al ser una cantidad bastante elevada de missings los eliminaremos de la base de datos.
Además eliminaremos de la base de datos la variable default y pdays, la primera por su dificil interpretación, y la segunda, ya que nos aporta la misma información que la variable *previous*. 

```{r}
bd <- bd[bd$na_count < 3, ] # Eliminamos si tiene más de 3 unkowns
bd <- bd[, -5] # Eliminamos default 
bd <- bd[, -12] # Eliminamos pdays
```

Siguiendo con el preproceso de los datos se ha decidido juntar categorias de la variable education, ya que de esta manera reducimos el número de categorias y se puede realizar un análisis más sencillo. Se han juntado aquellas categroias que tenian educación básica de 9 años o inferior en la categoria *basic.9y*.

```{r}
for (k in 1:nrow(bd)){
  if(bd$education[k] == 'basic.4y' | bd$education[k] == 'basic.6y' | bd$education[k] == 'basic.9y' | bd$education[k] == 'illiterate'){
    bd$education[k] <- 'basic.9y'
  }
} 
```


### Representación variable respuesta

Seguidamente mostraremos un gráfico donde se muestra, en porcentaje, la cantidad de respuestas para cada una de las dos categorias.

```{r}
fig <-  barplot(100*prop.table(table(bd$y)), col = "lightblue", main = "Contractacio diposit bancari", ylab = "%  clients",
                font.lab = 2, ylim = c(0,100), width = 0.5)

text(fig, 100*prop.table(table(bd$y)),  round(100*prop.table(table(bd$y)),3), cex= 1, pos = 3)
```

Se puede observar como la categoria *no* tiene un cantidad muy elevada de registros respecto los registros de la categoria *yes*


### Imputación missings

Para realizar la imputación de los valores faltantes, lo primero que hemos realizado, ha sido sobre las variables categoricas que son aquellas que para nuestra base de datos alberga valores missings, pero estos no estan bien formateados, por lo tanto para aquellos registros con una label *unknown* les hemos asignado un valor *NA*.

```{r}
 for(i in 1:nrow(bd)){
   for (j in 2:6){
     if(bd[i,j] == 'unknown'){
     bd[i,j] <- NA  
     } 
     }
 } 
```

Seguidamente hemos convertido estas variables en factores, para más adelante poder implementar un algoritmo de imputación de valores faltantes.

```{r}
bd[,(2:6)] <- lapply(bd[,2:6], as.factor)
 
 summary(bd)
```

Finalmente se ha realizado una imputación de los valores con el algoritmo de *mice*, con el método de *polyreg* que es el adecuado para utilizar variables categóricas. Finalmente asignamos los valores imputados a la base de datos y de esta manera ya no tenemos valores faltantes.

```{r}
 imp_mice <- mice(bd[,2:6], m=1, meth = "polyreg" )
 summary(imp_mice)
 summary(complete(imp_mice))
 imp_mice2 <- complete(imp_mice)

 bd[,2:6] <- imp_mice2 
```


# Análisis de los datos.

Antes de poder realizar cualquier tipo de análisis vamos a realizar una *factorización* de las variables categóricas para así poder analizar mejor los datos.

```{r}
levels(bd$y) <- c(0,1)
bd$y <- as.factor(bd$y) # convertimos la varible respuesta a factor
bd[sapply(bd, is.character)] <- lapply(bd[sapply(bd, is.character)], 
                                       as.factor)
```

Seguidamente para poder realizar un buen estudio separaremos nuestra base de datos en dos conjuntos, uno de entrenamiento y otro de validación. Con el primero lo que haremos será crear el modelo predictivo y conseguir el mejor ajuste posible, y seguidamente con el conjunto de validación comprobaremos que tan bueno es el ajuste. 

```{r}
n <- nrow(bd)

set.seed(23531)
learn <- sample(1:n, round(0.75*n))


nlearn <- length(learn)
ntest <- n - nlearn
set.seed(23531)
valid <- sample(1:nlearn, round(0.25*nlearn))
train <- learn[-valid]
```


Seguidamente creamos un primer modelo, este modelo lo que pretende encontrar es la relación de las variables *age, job, marital, education, housing, loan, contact, month, day_of_week, duration, campaign, previous, poutcome*.

Al tener una variable respuesta del tipo categórica binaria se realizará una regresión logística.

```{r}
summary(bd)
bd$age <- as.numeric(bd$age)
modelo_1 <- glm(y~ 
                age + job + marital + education + housing+
                loan + contact + month + day_of_week + duration
                + campaign + previous + poutcome
                , data = bd[train,], family = binomial(link = logit))

summary(modelo_1)
```


# Resolución del problema

Finalmente valoraremos el ajuste de nuestro modelo calculando la matriz de confusión y el accuracy del modelo, además de una representación gráfica del ajuste del modelo, con la curva ROC.

```{r}
pred <- predict.glm(modelo_1, newdata=bd[train,], type="response")
pred_train <- ifelse(pred > 0.5, 1, 0)
pred_train <- factor(pred_train, levels = c("0", "1"), labels = c("No Contrata", "Contrata"))

```

```{r}
matrizConfusion <- table(bd[train,]$y, pred_train)
matrizConfusion
```


Para realizar el cálculo de la accuracy se debe realizar sobre la predicción realizada con el conjunto de datos de validación.

```{r}
pred_valid <- predict(modelo_1, type = 'response', newdata = bd[valid,])
pred_valid <- ifelse(pred_valid > 0.5, 1, 0)
pred_valid <- factor(pred_valid, levels = c("0", "1"), labels = c("No Contrata", "Contrata"))
matrizConfusion <- table(bd[valid,]$y, pred_valid)
matrizConfusion
```

```{r}
vp <- matrizConfusion[1,1]
fn <- matrizConfusion[1,2]
vn <- matrizConfusion[2,2]
fp <- matrizConfusion[2,1]
total <- (vp+vn+fn+fp)

accuracy <- (vp + vn)/total
error_rate <- (fp+fn)/total
recall <- vp/(vp+fp)
especificity <- vn/(vn+fn)
```

Las métricas obtenidas son las siguientes

| Metric| Value |
|-------|-------|
|Accuracy| `r accuracy`|
|Error rate | `r error_rate`|
|Recall| `r recall`|
|Especificity | `r especificity`|

Como se puede observar el performance de todos las métricas es bastante bueno, por lo que a prioriri el ajuste del modelo parece ser bastante bueno. El único cálculo que vemos más alejado de tener unos buenos números es el de la Especificidad, la qual se puede observar como solo el `r especificity*100`% es clasificado como negativo cuando de verdad es negativo, en nuestro caso concreto, solo el `r especificity*100`% de las personas que contratan el crédito son clasificadas correctamente.

Seguidamente realizaremos un estudio con más profundidad a través de la curva ROC i así esclarecer si realmente el modelo presentado es un buen clasificador y, por lo tanto, predice con bastante exactitud nuestros datos.

```{r}
pred1 <- prediction(as.numeric(pred_valid), as.numeric(bd[valid,]$y))
perf1 <- performance(pred1, "tpr", "fpr")
plot(perf1)
```

Como podemos observar la curva ROC no se aleja mucho de la diagonal, por lo que se puede concluir que pese a que tengamos un accuracy bastante elevado la predicción no es muy buena. 
