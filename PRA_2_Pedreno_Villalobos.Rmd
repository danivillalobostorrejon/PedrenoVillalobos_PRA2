---
title: 'PRA2: Tipologia y Ciclo de Vida de los Datos'
author: "Oscar Pedreño y  Daniel Villalobos"
date: "5/22/2022"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    fig_width: 7
    fig_height: 6
  html_document: 
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/UOC/1r/2n Semestre/Tipologia y ciclo de vida de los datos/PRA2") # choose your own directory

set.seed(12)

if(!require(mice)){
    install.packages("mice")
    library(mice)
}

if(!require(ROCR)){
    install.packages("ROCR")
    library(ROCR)
}

# tinytex::install_tinytex()
 
```


# Definición del proyecto

En el siguiente proyecto de la asignatura, Tipologia y Ciclo de Vida de los Datos, del máster de la Universitat Oberta de Catalunya, trataremos de predecir el resultado de una campanya de marketing de un banco portuges a través de una base de datos encontrada en la página web UCI Machine Learning Repository. 

Se ha escogido esta temática ya que ambos integrantes del equipo procedemos de un area economica, ya sea de estudios, como en el ámbito laboral, por lo que esta base de datos, como veremos más adelante nos permitirá analizar ciertas variables economicas, mediante una regresión logística.

Como ya se ha comentado, se realizará un estudio de estos datos a través de un modelo de regresión logístico. Esto es debido a que nuestra variable respuesta, es una variable categórica con dos niveles, si la persona contactada no contrata o si la persona contactada contrata. Por lo tanto, creemos que la mejor manera de analizar estos datos es a través de un modelo logístico.

# Descripción del dataset

Las variables que se encuentran en este dataset son:

|Nombre| Tipo | Descripción | Valores |
|-------| ----| ------------| --------|
|age |Numérica| Edat de la persona contactada| |
| job| Categorica  nominal| Tipo de trabajo de la persona contactada| *Admin, blue-collar, entrepreneur, housemaid, management, retired, self-employed, services, Student, technician, unemployed*|
|marital |Categorica nominal|Estado civil de la persona contactada|*Divorced (divorciat/da o vidu/a), married, single*|
|education| Categorica  nominal|Nivel educativo de la persona contactada|*Basic.9y, high.school, professional.course, university.degree*|
|housing|Categorica binaria|Indica si la persona contactada tiene una hipoteca contratada|*Yes, no*|
|loan|Categorica binaria|Indica si la persona contactada tiene un crédito personal|*Yes, no*|
|contact|Categorica binaria|Tipo de comunicación que se ha realitzado|*Cellular, telephone*|
|month|Categorica nominal|Mes en que se ha contactado por última vez|*Jan, feb, ..., nov, dec*|
|day_of_week|Categorica nominal|Dia en que se ha contactat por última vez|*Mon, tue, wed, thu, fri.*|
|duration|Numérica contínua|Duración en segundos de el último contacto con la persona| |
|campaign|Numérica discreta|Número de veces que se ha contactado a la persona esta campaña| |
|previous|Numérica discreta|Número de veces que se ha contactado a la persona antes de esta campaña| |
|poutcome| Categorica nominal|Resultado de la campaña de marketing anterior|*Failure, nonexistent, success*|
|emp.var.rate|Numérica contínua|Tasa de varicación de la ocupación del momento en que se ha contactado (Indicador trimestral)| |
|cons.price.idx|Numérica contínua|Indice de precio del consumidor (Indicador mensual)| |
|cons.conf.idx|Numérica contínua |Indice de confianza del consumidor (Indicador mensual)| |
|euribor3m|Numérica contínua|Euribor a 3 meses en el dia del contacto (Indicador diario)| |
|nr.employed|Numérica discreta|Número de trabajadores en la entidad bancaria en el momento del contacto| |
|y|Categorica binaria|Indica si el cliente ha contratado un diposito bancario durante esta campaña|*Yes, no*|


Se han eliminado dos variables de la base de datos original (*default* y *pdays*), ya que, en el primer caso no se sabia interpretar el significado de la variable, y en el segundo caso porque no aportaba más información que la que ya aporta la variable *previous*.

Como ya se ha explicado, la variable respuesta que utilizaremos será, el resultado de la campaña, es decir, si un cliente contratará el crédito durante la campaña o no. En la base de datos esta información esta recogida en la variable *y*.

# Integración y selección de los datos de interés a analizar

Para empezar el análisis primero debemos realizar una lectura de los datos:

```{r}
bd <- read.csv2("bank-additional-full.csv")
head(bd)
```

# Limpieza de los datos.

Seguidamente realizaremos un análisis univariante de las distintas variables para poder observar con que clase de valores estamos tratando.

### Representación gráfica

Como se puede observar la variable *age* contiene valores entre los `r min(bd$age)` y los `r max(bd$age)` años. La media de edad son `r mean(bd$age)`. Se observan varios valores outliers en estos datos, aunque no creemos que estos valores vayan a influenciar en el análisis, ya que son valores de entre 65 años y `r max(bd$age)`, por lo tanto pueden ser valores de edad totalmente asumibles por una persona.

```{r}
hist(bd$age)
boxplot(bd$age)
```

Observamos como las categorias predominantes, para la varible *job* son, *admin, blue-collar, technician*. Además observamos una pequeña sección de registros con un valor *unknown*, estos valores más adelante serán tratados como valores missing. La cantidad de estos valores es: `r length(which(bd$job == "unknown"))`.

```{r}
barplot(prop.table(table(bd$job)))
```


En lo que refiere al estado civil de la persona contactada, observamos como el grupo dominante son personas casadas, además observamos una proporción de valores *unkwnon*, que como en el caso de la variable *job* serán tratados como valores faltantes. Tenemos `r length(which(bd$marital == "unknown"))` valores *unknown*

```{r}
barplot(prop.table(table(bd$marital)))
prop.table(table(bd$marital))
```


De las personas contactadas el gran grueso se clasifica como personas con un mínimo de estudios secundarios, ya que, las categroias de *high.school y university.degree* suman más del 50%. Se observan `r length(which(bd$education == "unknown"))` de valores *unknown*.

```{r}
barplot(prop.table(table(bd$education)))
```


De las personas contratadas no se observa una gran diferencia entra las personas que ya tienen una hipoteca contratada o no, ya que ambos valores oscilan cerca del 50%. Podemos obervar como tenemos `r length(which(bd$housing == "unknown"))` de valores *unknown*.

```{r}
barplot(prop.table(table(bd$housing)))
```

De las personas contactadas se observa como en su mayoria, algo más del 80%, no tienen contratado un crédito personal. Podemos obervar como tenemos `r length(which(bd$loan == "unknown"))` de valores *unknown*

```{r}
barplot(prop.table(table(bd$loan)))
```

Se observa como el contacto de las personas se ha realizado o vía teléfono fijo o vía teléfono móvil. Se ve como la mayoria de llamadas han sido via teléfono móvil.

```{r}
barplot(prop.table(table(bd$contact)))
```

Se observa como la proporción de llamadas es mayor en mayo que en los demás meses, y si hacemos un poco de zoom hacia fuera, vemos como el gran grueso de llamadas se realiza en los meses de verano. 

```{r}
barplot(prop.table(table(bd$month)))
```

No se observan diferencias entre los distintos días de la semana, lo que si podemos observar es como no hay llamadas fuera de los horarios estandard, es decir no hay llamadas en fin de semana.

```{r}
barplot(prop.table(table(bd$day_of_week)))
```

Observamos comom la gran mayoria de llamadas tienen una duración corta, de media tienen una duración de `r mean(bd$duration)` segundos, pero en este caso tiene más sentido mirar la mediana, ya que valores elevados pueden influenciar sobre el valor de la media, en cuanto a la mediana observamos que las llamadas duran `r median(bd$duration)`. Por lo que no son llamadas muy largas.


```{r}
hist(bd$duration, breaks= 100)
```


Se observa como la mediana de esta variable es `r median(bd$campaign)` por lo que se puede obervar que en su gran mayoria, las personas de esta campaña no han sido contactadas muchas veces. 

```{r}
hist(bd$campaign)
summary(bd$campaign)
```


Se observa como la mediana de esta variable es `r median(bd$previous)` por lo que se puede obervar que en su gran mayoria, las personas de esta campaña no habian sido contactadas con anterioridad. 


```{r}
hist(bd$previous)
```

De las personas que anteriormente habian sido contactadas la gran mayoria no contrataron el producto bancario, pero se observa como de las personas de la campaña actual, un gran grueso de estos individuos son nuevos.

```{r}
barplot(table(bd$poutcome))
```


Las siguientes varibles representan distintos indicadores económicos, como la variación mensual del trabajo o el IPC mensual. Los englobaremos todos en la categroria de **Situación Economica actual**. De las cuales por el momento no hay gran cosa a destacar.

```{r}
table(bd$emp.var.rate) #VARIACIÓN TRABAJO TRIMESTRAL
```


```{r}
table(bd$cons.price.idx) #IPC MENSUAL
```


```{r}
table(bd$cons.conf.idx) # INDICE DE CONFIANZA CONSUMIDOR
```


```{r}
table(bd$euribor3m) #EURIBOR A TRES MESES POR DIA
```


```{r}
table(bd$nr.employed) #TREBALLADOR PER TRIMESTRE
```

### Conteo de missings i eliminación

Realizaremos un breve análisis de los valores missings en cada uno de los registros, esto nos dara un poco más de información de como esta estructurada la base de datos.

```{r}
for (i in 1:nrow(bd)){
  
  bd$na_count[i] <- sum(bd[i,] == 'unknown') 
  
}
table(bd$na_count)
```

Como se muestra en la tabla de arriba, hay registros con hasta 5 valores missing, de los cuales, aquellos que tengan más de 3 valores faltantes por registro, al ser una cantidad bastante elevada de missings los eliminaremos de la base de datos.
Además eliminaremos de la base de datos la variable default y pdays, la primera por su dificil interpretación, y la segunda, ya que nos aporta la misma información que la variable *previous*. 

```{r}
bd <- bd[bd$na_count < 3, ] # Eliminamos si tiene más de 3 unkowns
bd <- bd[, -5] # Eliminamos default 
bd <- bd[, -12] # Eliminamos pdays
```

Siguiendo con el preproceso de los datos se ha decidido juntar categorias de la variable education, ya que de esta manera reducimos el número de categorias y se puede realizar un análisis más sencillo. Se han juntado aquellas categroias que tenian educación básica de 9 años o inferior en la categoria *basic.9y*.

```{r}
for (k in 1:nrow(bd)){
  if(bd$education[k] == 'basic.4y' | bd$education[k] == 'basic.6y' | bd$education[k] == 'basic.9y' | bd$education[k] == 'illiterate'){
    bd$education[k] <- 'basic.9y'
  }
} 
```


### Representación variable respuesta

Seguidamente mostraremos un gráfico donde se muestra, en porcentaje, la cantidad de respuestas para cada una de las dos categorias.

```{r}
fig <-  barplot(100*prop.table(table(bd$y)), col = "lightblue", main = "Contractacio diposit bancari", ylab = "%  clients",
                font.lab = 2, ylim = c(0,100), width = 0.5)

text(fig, 100*prop.table(table(bd$y)),  round(100*prop.table(table(bd$y)),3), cex= 1, pos = 3)
```

Se puede observar como la categoria *no* tiene un cantidad muy elevada de registros respecto los registros de la categoria *yes*

Profundizando en el análisis podemos observar como las personas que si han aceptado el credito  bancario tienen de media una duración de llamada más elevada que las personas que no han contratado este producto.

```{r}
aggregate(duration~y, data= bd, mean)
```


### Imputación missings

Para realizar la imputación de los valores faltantes, lo primero que hemos realizado, ha sido sobre las variables categoricas que son aquellas que para nuestra base de datos alberga valores missings, pero estos no estan bien formateados, por lo tanto para aquellos registros con una label *unknown* les hemos asignado un valor *NA*.

```{r}
 for(i in 1:nrow(bd)){
   for (j in 2:6){
     if(bd[i,j] == 'unknown'){
     bd[i,j] <- NA  
     } 
     }
 } 
```

Seguidamente hemos convertido estas variables en factores, para más adelante poder implementar un algoritmo de imputación de valores faltantes.

```{r}
bd[,(2:6)] <- lapply(bd[,2:6], as.factor)
 
 summary(bd)
```

Finalmente se ha realizado una imputación de los valores con el algoritmo de *mice*, con el método de *polyreg* que es el adecuado para utilizar variables categóricas. Finalmente asignamos los valores imputados a la base de datos y de esta manera ya no tenemos valores faltantes.

```{r}
 imp_mice <- mice(bd[,2:6], m=1, meth = "polyreg" )
 summary(imp_mice)
 summary(complete(imp_mice))
 imp_mice2 <- complete(imp_mice)

 bd[,2:6] <- imp_mice2 
```


# Análisis de los datos.

Antes de poder realizar cualquier tipo de análisis vamos a realizar una *factorización* de las variables categóricas para así poder analizar mejor los datos.

```{r}
levels(bd$y) <- c(0,1)
bd$y <- as.factor(bd$y) # convertimos la varible respuesta a factor

bd[sapply(bd, is.character)] <- lapply(bd[sapply(bd, is.character)], 
                                       as.factor)

bd$month <- factor(bd$month, levels = c("mar","apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"))
bd$day_of_week <- factor(bd$day_of_week, levels = c("mon", "tue", "wed", "thu", "fri"))
bd$age <- as.numeric(bd$age)
```

Seguidamente para poder realizar un buen estudio separaremos nuestra base de datos en dos conjuntos, uno de entrenamiento y otro de validación. Con el primero lo que haremos será crear el modelo predictivo y conseguir el mejor ajuste posible, y seguidamente con el conjunto de validación comprobaremos que tan bueno es el ajuste. 

```{r}
n <- nrow(bd)

set.seed(23531)
learn <- sample(1:n, round(0.75*n))


nlearn <- length(learn)
ntest <- n - nlearn
set.seed(23531)
valid <- sample(1:nlearn, round(0.25*nlearn))
train <- learn[-valid]
```


Seguidamente creamos un primer modelo, este modelo lo que pretende encontrar es la relación de las variables *age, job, marital, education, housing, loan, contact, month, day_of_week, duration, campaign, previous, poutcome*.

Al tener una variable respuesta del tipo categórica binaria se realizará una regresión logística.

```{r}
modelo_1 <- glm(y~ 
                age + job + marital + education + housing+
                loan + contact + month + day_of_week + duration
                + campaign + previous + poutcome
                , data = bd[train,], family = binomial(link = logit))

summary(modelo_1)
```

Del modelo que hemos construido podemos observar como la variable *duration*, que hemos analizado anterorimente tiene un efecto positivo sobre el resultado de la campaña, además se puede observar como el lunes, dia base, es el peor dia para realizar llamadas, y que en proporcion de aceptación de llamadas el mejor més es marzo. También se puede comprobar como las personas que han sido contactadas con anterioridad son más propensas a aceptar.

El valor de Akaike nos muestra que el modelo, al tener demasiados registros, nos muestra un valor bastante alejado, pero aun así se podría pensar por el momento de que el modelo recoge bastante información de los datos y que puede ser un buen predictor. Seguidamente realizaremos el análisis predictivo correspondiente para analizar la performance de este modelo.


# Resolución del problema

Finalmente valoraremos el ajuste de nuestro modelo calculando la matriz de confusión y el accuracy del modelo, además de una representación gráfica del ajuste del modelo, con la curva ROC.

```{r}
pred <- predict.glm(modelo_1, newdata=bd[train,], type="response")
pred_train <- ifelse(pred > 0.5, 1, 0)
pred_train <- factor(pred_train, levels = c("0", "1"), labels = c("No Contrata", "Contrata"))

```

```{r}
matrizConfusion <- table(bd[train,]$y, pred_train)
matrizConfusion
```


Para realizar el cálculo de la accuracy se debe realizar sobre la predicción realizada con el conjunto de datos de validación.

```{r}
pred_valid <- predict(modelo_1, type = 'response', newdata = bd[valid,])
pred_valid <- ifelse(pred_valid > 0.5, 1, 0)
pred_valid <- factor(pred_valid, levels = c("0", "1"), labels = c("No Contrata", "Contrata"))
matrizConfusion <- table(bd[valid,]$y, pred_valid)
matrizConfusion
```

```{r}
vp <- matrizConfusion[1,1]
fn <- matrizConfusion[1,2]
vn <- matrizConfusion[2,2]
fp <- matrizConfusion[2,1]
total <- (vp+vn+fn+fp)

accuracy <- (vp + vn)/total
error_rate <- (fp+fn)/total
recall <- vp/(vp+fp)
especificity <- vn/(vn+fn)
```

Las métricas obtenidas son las siguientes

| Metric| Value |
|-------|-------|
|Accuracy| `r accuracy`|
|Error rate | `r error_rate`|
|Recall| `r recall`|
|Especificity | `r especificity`|

Como se puede observar el performance de todos las métricas es bastante bueno, por lo que a prioriri el ajuste del modelo parece ser bastante bueno. El único cálculo que vemos más alejado de tener unos buenos números es el de la Especificidad, la qual se puede observar como solo el `r especificity*100`% es clasificado como negativo cuando de verdad es negativo, en nuestro caso concreto, solo el `r especificity*100`% de las personas que contratan el crédito son clasificadas correctamente.

Seguidamente realizaremos un estudio con más profundidad a través de la curva ROC i así esclarecer si realmente el modelo presentado es un buen clasificador y, por lo tanto, predice con bastante exactitud nuestros datos.

```{r}
pred1 <- prediction(as.numeric(pred_valid), as.numeric(bd[valid,]$y))
perf1 <- performance(pred1, "tpr", "fpr")
plot(perf1)
```

Como podemos observar la curva ROC no se aleja mucho de la diagonal, por lo que se puede concluir que pese a que tengamos un accuracy bastante elevado la predicción no es muy buena. 
